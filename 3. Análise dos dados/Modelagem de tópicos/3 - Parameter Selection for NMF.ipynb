{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Selection for NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the more advanced task of parameter selection for NMF topic modelling - namely, selecting a useful value for the number of topics *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load the TF-IDF normalised document-term matrix and list of terms that we stored earlier using *Joblib*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:49:37.147732Z",
     "start_time": "2021-05-22T02:49:36.618150Z"
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "(A, terms, snippets) = joblib.load(\"cenario1-tweets-tfidf.pkl\")\n",
    "\n",
    "print(\"Loaded %d X %d document-term matrix\" % (A.shape[0], A.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Topic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common approach for parameter selection is to Measure and compare the topic coherence of models generated for different values of *k*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to start by pre-specifying an initial range of \"sensible\" values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:49:37.151886Z",
     "start_time": "2021-05-22T02:49:37.149457Z"
    }
   },
   "outputs": [],
   "source": [
    "kmin, kmax = 5, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply NMF for each of these values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:09.086072Z",
     "start_time": "2021-05-22T02:49:37.153554Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "topic_models = []\n",
    "\n",
    "# try each value of k\n",
    "for k in range(kmin, kmax + 1, 5):\n",
    "    print(\"Applying NMF for k=%d ...\" % k)\n",
    "    # run NMF\n",
    "    model = decomposition.NMF(init=\"nndsvd\", n_components=k)\n",
    "    W = model.fit_transform(A)\n",
    "    H = model.components_\n",
    "    # store for later\n",
    "    topic_models.append((k, W, H))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To select the number of topics, here we will use a *topic coherence* measure called TC-W2V. This measure relies on the use of a *word embedding* model constructed from our corpus. So in this step we will use the *Gensim* implementation of Word2Vec to build a Word2Vec model based on our collection of news articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you want to skip this step, a pre-built Word2Vec model for the sample dataset [is also provided here for download](http://erdos.ucd.ie/files/pydata/w2v-model.bin) (71MB)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read the documents from the input file again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:09.209722Z",
     "start_time": "2021-05-22T02:50:09.088243Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "\n",
    "raw_documents = []\n",
    "\n",
    "with open(os.path.join(\"tweets_pt.txt\"), \"r\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        raw_documents.append(line.strip().lower())\n",
    "\n",
    "print(\"Read %d raw text documents\" % len(raw_documents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the custom stopword list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:09.217023Z",
     "start_time": "2021-05-22T02:50:09.211570Z"
    }
   },
   "outputs": [],
   "source": [
    "custom_stop_words = []\n",
    "\n",
    "with open(\"portuguese.txt\", \"r\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        custom_stop_words.append(line.strip().lower())\n",
    "\n",
    "# note that we need to make it hashable\n",
    "print(\"Stopword list has %d entries\" % len(custom_stop_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting the Number of Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also define a function to get the topic descriptor (i.e. list of top terms) for each topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:58.286125Z",
     "start_time": "2021-05-22T02:50:58.277495Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_descriptor(all_terms, H, topic_index, top):\n",
    "    # reverse sort the values to sort the indices\n",
    "    top_indices = np.argsort(H[topic_index, :])[::-1]\n",
    "    \n",
    "    # now get the terms corresponding to the top-ranked indices\n",
    "    top_terms = []\n",
    "    \n",
    "    for term_index in top_indices[0:top]:\n",
    "        top_terms.append(all_terms[term_index])\n",
    "    \n",
    "    return top_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the Final  Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 t贸picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.932368Z",
     "start_time": "2021-05-22T02:50:59.929810Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 5 \n",
    "\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[0][1]\n",
    "H = topic_models[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the topic descriptors for this model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.944926Z",
     "start_time": "2021-05-22T02:50:59.934190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 5)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.954811Z",
     "start_time": "2021-05-22T02:50:59.946336Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.964236Z",
     "start_time": "2021-05-22T02:50:59.956505Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 15)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.973604Z",
     "start_time": "2021-05-22T02:50:59.965976Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 20)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10 t贸picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.979710Z",
     "start_time": "2021-05-22T02:50:59.975323Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 10 \n",
    "\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[1][1]\n",
    "H = topic_models[1][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:50:59.994060Z",
     "start_time": "2021-05-22T02:50:59.981520Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 5)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.005515Z",
     "start_time": "2021-05-22T02:50:59.996040Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.015605Z",
     "start_time": "2021-05-22T02:51:00.007294Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 15)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.025113Z",
     "start_time": "2021-05-22T02:51:00.017259Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 20)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T01:35:40.549034Z",
     "start_time": "2021-05-18T01:35:40.547094Z"
    }
   },
   "source": [
    "# 15 t贸picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.037453Z",
     "start_time": "2021-05-22T02:51:00.026780Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 15\n",
    "\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[2][1]\n",
    "H = topic_models[2][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.053072Z",
     "start_time": "2021-05-22T02:51:00.039112Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 5)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.063644Z",
     "start_time": "2021-05-22T02:51:00.054494Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.073233Z",
     "start_time": "2021-05-22T02:51:00.065049Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 15)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.083119Z",
     "start_time": "2021-05-22T02:51:00.074704Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 20)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 t贸picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.087472Z",
     "start_time": "2021-05-22T02:51:00.084639Z"
    }
   },
   "outputs": [],
   "source": [
    "k = 20 \n",
    "\n",
    "# get the model that we generated earlier.\n",
    "W = topic_models[3][1]\n",
    "H = topic_models[3][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.103272Z",
     "start_time": "2021-05-22T02:51:00.088884Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 5)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.114091Z",
     "start_time": "2021-05-22T02:51:00.104874Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 10)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.124904Z",
     "start_time": "2021-05-22T02:51:00.115561Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 15)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20 termos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T02:51:00.135691Z",
     "start_time": "2021-05-22T02:51:00.126274Z"
    }
   },
   "outputs": [],
   "source": [
    "for topic_index in range(k):\n",
    "    descriptor = get_descriptor( terms, H, topic_index, 20)\n",
    "    str_descriptor = \", \".join( descriptor )\n",
    "    print(\"Topic %02d: %s\" % ( topic_index+1, str_descriptor ) )"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "91px",
    "width": "373px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "557px",
    "left": "22px",
    "top": "170px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
